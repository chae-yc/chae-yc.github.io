I"<p>본 글은
<strong>Byungchul Tak &amp; Seorin Park &amp; Prabhakar Kudva, 2019. “Priolog: Mining Important Logs via Temporal Analysis and Prioritization,” Sustainability, MDPI, Open Access Journal, vol. 11(22), pages 1-17, November.</strong>
를 읽고 개인적으로 정리한 글입니다.
문제가 발생될 시 포스트를 삭제하도록 하겠습니다.</p>

<h2 id="abstract">Abstract</h2>

<p>IT service들 운영을 관리하기 위해서 Log analytics는 중요한 부분이다.
소프트웨어가 복잡해지면서 많은 수의 로그 중에서 problem diagnosis를 위한 의미있는 데이터를 찾아내는 것이 힘들어지고 있다.
본 논문에서는 중요하고 연관성 높은 로그들의 집합으로 만들 수 있는 새로운 기술인 Priolog라는 기술을 소개한다.
Priolog는 log template temporal analysis, log template frequency analysis, word frequency analysis의 조합을 통해서 분석해서 중요한 로그의 순위를 매겨준다.
이 기술을 구현하여 popular한 OpenStack platform의 problem diagnosis task에 적용했다.
분석 결과에 따르면 Priolog는 여러 시나리오에서 실패 원인에 대한 직접적인 힌트를 담고있는 중요한 로그를 효과적으로 찾을 수 있다.
논문에서 기술의 개념, 디자인 및 실제 로그를 사용한 평가 결과를 보여준다.</p>

<blockquote>
  <p>Keywords: log analysis; problem diagnosis; temporal correlation; log template; hierarchical clustering</p>
</blockquote>

<h2 id="1-introduction">1. Introduction</h2>

<p>오늘날 IT 서비스 관리에는 로그 분석 기능이 반드시 필요하다.
로그 메시지는 서비스의 상태 나 문제에 대한 직접적인 힌트로 사용될 수 있다.
containerization [7], micro-service [8,9], serverless computing [10]의 예들 처럼 작은 컴포넌트들을 여러 개 사용하는 것으로 같은 software architecture paradigm이 바뀌고 있다.
각 컴포넌트들이 각자의 log stream을 만들기 때문에 powerful search functions, text pattern matching, aggretation tools를 사용하더라도
로그의 양과 복잡성 때문에 시스템 운영이 어려워진다.
또한 클라우드 소프트웨어의 variety와 diversity로 인해 소프트웨어 및 시스템에서 생성 된 로그는 format, levels of detail, content가 매우 다른 경향이 있다.</p>

<p>로그를 사용한 searvice failure를 진단하기 위해 이 분야에서 다양한 접근 방식이 제안되어왔다.
대부분의 연구는 failure가 발생한 후 anomalies 또는 outliers를 detect하는 데 중점을 둔다 [11–17].
Log analysis은 data mining 그리고 AI 기술을 적용하기에 좋은 타겟이어왔다 [18].
많은 기술이 이용 가능하지만, 이전의 연구에서는 클라우드 운영 환경에서 실제 중요성과 관련성을 드러내기보다는
post-mortem analysis(사후 분석)을 통해 anomlies detect하거나
모니터링된 데이터의 statistical analysis 만을 제공한다.
따라서, 운영자가 면밀한 검사를 위해서는 관련된 log set로 신속하게 좁혀 나갈 수 있게 만들어야 한다는 과제가 여전히 남아있다.</p>

<p>게다가, 클라우드 환경들은 apllications, system software, patches, cluster provisioning, tenancy(차용: 여러 사용자가 동시에 사용) 그리고 configuration을 변경하는 것이 포함된다.

통계적으로 드물게 발생하지만, anomalies나 outliers가 감지되더라도 실제 복잡한 cloud setting에서는 operational context에 맞춰서 정상적일 수도 있다.
(예: 드물지만 정상적인 load changes, software update and pathces, routine configuration modifications, system utilization changes)
복잡성을 없애기 위해 모니터링 도구 및 분석 기술의 사용이 증가함에 따라 잘못된 경보가 많이 발생하여 시스템 관리자가 파악하기가 힘들다.
또한, 다양한 로그 유형은 개발자에게도 과제를 부여한다.
따라서 clouad operational domain context에서 analytics 또는 AI identified statistical outliers가 필터링되거나 적어도 중요성에 따라 정렬되는 것이 핵심이다.
이상적인 로그 기반 경고 시스템은 outliers를 예측하기 위해 outlier들 끼리의 correlation(상관 관계)를 검토할 뿐만 아니라 active system operation들 간의 temporal correlations도 검토해야한다. (예 : 계획된 구성 변경, 계획되거나 계획되지 않은 유지 관리 일정,로드 패턴, 일일 상태 점검 실행, 화이트리스트, 기타.). 이 운영 영역 지식을 AI 및 분석과 통합하고 연관시키는 것이 이상적인 목표입니다.</p>

<h2 id="의문점">의문점</h2>

<ol>
  <li></li>
</ol>
:ET