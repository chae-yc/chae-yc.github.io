I"<p>본 글은
<strong>Byungchul Tak &amp; Seorin Park &amp; Prabhakar Kudva, 2019. “Priolog: Mining Important Logs via Temporal Analysis and Prioritization,” Sustainability, MDPI, Open Access Journal, vol. 11(22), pages 1-17, November.</strong>
를 읽고 개인적으로 정리한 글입니다.
문제가 발생될 시 포스트를 삭제하도록 하겠습니다.</p>

<h2 id="abstract">Abstract</h2>

<p>IT service들 운영을 관리하기 위해서 Log analytics(로그 분석기s)는 중요한 부분인데 소프트웨어가 복잡해지면서 많은 수의 로그 중에서 problem diagnosis를 위한 의미있는 데이터를 찾아내는 것이 힘들어지고 있다. 본 논문에서는 중요하고 연관성 높은 로그들의 집합으로 만들 수 있는 새로운 기술인 Priolog라는 기술을 소개한다.
Priolog는 log template temporal analysis, log template frequency analysis, word frequency analysis의 조합을 통해서 분석해서 중요한 로그의 순위를 매겨준다.
이 기술을 구현하여 popular한 OpenStack platform의 problem diagnosis task에 적용했다.
분석 결과에 따르면 Priolog는 여러 시나리오에서 실패 원인에 대한 직접적인 힌트를 담고있는 중요한 로그를 효과적으로 찾을 수 있다.
논문에서 기술의 개념, 디자인 및 실제 로그를 사용한 평가 결과를 보여준다.</p>

<blockquote>
  <p>Keywords: log analysis; problem diagnosis; temporal correlation; log template; hierarchical clustering</p>
</blockquote>

<h2 id="1-introduction">1. Introduction</h2>

<p>오늘날 IT 서비스 관리에는 로그 분석 기능이 반드시 필요하다.
로그 메시지는 서비스의 상태 나 문제에 대한 직접적인 힌트로 사용되거나 시계열 분석을 적용하여 흥미로운 시간 패턴을 학습하는 일반적인 시계열 데이터로 볼 수 있습니다.
로그를 분석하는 기능은 최신 IT 서비스에 중요하지만 실행 가능한 통찰력을 제공하기 위해 로그 분석을 대규모로 수행하는 것이 훨씬 어려워지고 있습니다.
가장 큰 이유는 대량의 로그 데이터입니다.
컨테이너화 [7], 마이크로 서비스 [8,9] 및 서버리스 컴퓨팅 [10]과 같은 소프트웨어 아키텍처 패러다임은 각각 자체 로그 스트림을 생성하는 더 작은 수의 작은 구성 요소를 향해 나아가고 있습니다.
강력한 검색 기능, 텍스트 패턴 일치 및 집계 도구를 사용하더라도 시스템 운영자는 볼륨과 복잡성에 빠르게 압도됩니다.
또한 클라우드 소프트웨어의 다양성과 다양성으로 인해 소프트웨어 및 시스템에서 생성 된 로그는 형식, 세부 수준 및 내용이 매우 다른 경향이 있습니다.
로그를 사용하여 서비스 오류를 진단하기 위해이 필드에서 다양한 접근 방식이 제안되었습니다.
대부분의 연구는 장애가 발생한 후 로그에서 이상 또는 이상 치를 탐지하는 데 중점을 둡니다 [11–17].
로그 분석은 데이터 마이닝 및 AI 기술을 적용하기위한 좋은 목표였습니다 [18].</p>

<h2 id="의문점">의문점</h2>

<ol>
  <li></li>
</ol>
:ET